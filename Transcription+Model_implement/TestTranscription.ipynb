{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process\n",
    "from jiwer import wer\n",
    "from rapidfuzz.distance import Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity and Accuracy index for first Transcribe sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are aligned for comparison.\n",
      "Comparison results saved to: C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\Comparison_Results.csv\n",
      "Total Sentences: 340\n",
      "Exact Match Accuracy: 6.47%\n",
      "Average Similarity Score: 86.74%\n",
      "Average Word Error Rate (WER): 0.46\n",
      "Top 5 Mismatched Sentences:\n",
      "                                    Corrected Sentence  \\\n",
      "199  আজকে পুরোনো বন্ধুদের সাথে দেখা হয়েছে, অনেক কথ...   \n",
      "338  তুমি পড়ালেখার পাশাপাশি ইন্টার্নশিপ করো, কাজে ...   \n",
      "276    এইবার ছুটিতে বন্ধুদের সাথে পাহাড়ে বেড়াতে যাব।   \n",
      "312    খুব ব্যস্ত দিন কাটালাম, এখন একটু বিশ্রাম দরকার।   \n",
      "122       তোমার পোশাকের ধরন আমার খুব একটা ভালো লাগেনি।   \n",
      "\n",
      "                                  Transcribed Sentence  Exact Match  \\\n",
      "199  আজকে পুরনো বন্ধুদের সাথে দেখা হয়েছে, অনেক কথা...            0   \n",
      "338  তুমি পড়ালেখার পাশাপাশি ইন্টারনশিপ করো, কাজে আ...            0   \n",
      "276   এইবার ছুটিতে বন্ধুদের সাথে পাহাড়ে বেড়াতে যাবে।            0   \n",
      "312     খুব ব্যস্ত দিন কাটালাম এখন একটু বিশ্রাম দরকার।            0   \n",
      "122      তোমার পোশাকের ধরন আমার খুব একটা ভালো লাগে নি।            0   \n",
      "\n",
      "     Similarity Score (%)  Edit Distance  Word Error Rate (WER)  \n",
      "199             99.029126              1               0.111111  \n",
      "338             99.009901              1               0.142857  \n",
      "276             98.947368              1               0.142857  \n",
      "312             98.924731              1               0.125000  \n",
      "122             98.876404              1               0.250000  \n"
     ]
    }
   ],
   "source": [
    "# Load the corrected and transcribed datasets\n",
    "corrected_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\CorrectSen - dementia.csv\"\n",
    "corrected_non_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\CorrectSen - NonDementia.csv\"\n",
    "\n",
    "transcribed_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\Dementia_Transcriptions.csv\"\n",
    "transcribed_non_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\NonDementia_Transcriptions.csv\"\n",
    "\n",
    "# Load datasets into DataFrames\n",
    "corrected_dementia_df = pd.read_csv(corrected_dementia_path)\n",
    "corrected_non_dementia_df = pd.read_csv(corrected_non_dementia_path)\n",
    "\n",
    "transcribed_dementia_df = pd.read_csv(transcribed_dementia_path)\n",
    "transcribed_non_dementia_df = pd.read_csv(transcribed_non_dementia_path)\n",
    "\n",
    "# Combine corrected and transcribed datasets for comparison\n",
    "corrected_df = pd.concat([corrected_dementia_df, corrected_non_dementia_df]).reset_index(drop=True)\n",
    "transcribed_df = pd.concat([transcribed_dementia_df, transcribed_non_dementia_df]).reset_index(drop=True)\n",
    "\n",
    "# Ensure the datasets are aligned\n",
    "if len(corrected_df) != len(transcribed_df):\n",
    "    print(\"Warning: The datasets have different numbers of sentences!\")\n",
    "else:\n",
    "    print(\"Datasets are aligned for comparison.\")\n",
    "\n",
    "# Compare sentences\n",
    "results = []\n",
    "for index, row in corrected_df.iterrows():\n",
    "    corrected_sentence = row['sentences']  # Assuming 'sentences' column in corrected_df\n",
    "    transcribed_sentence = transcribed_df.loc[index, 'transcribed_text']  # 'transcribed_text' in transcribed_df\n",
    "\n",
    "    # Calculate metrics\n",
    "    exact_match = int(corrected_sentence.strip() == transcribed_sentence.strip())\n",
    "    similarity_score = fuzz.ratio(corrected_sentence, transcribed_sentence)\n",
    "    edit_distance = Levenshtein.distance(corrected_sentence, transcribed_sentence)  # Updated line\n",
    "    sentence_wer = wer(corrected_sentence, transcribed_sentence)\n",
    "\n",
    "\n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Corrected Sentence': corrected_sentence,\n",
    "        'Transcribed Sentence': transcribed_sentence,\n",
    "        'Exact Match': exact_match,\n",
    "        'Similarity Score (%)': similarity_score,\n",
    "        'Edit Distance': edit_distance,\n",
    "        'Word Error Rate (WER)': sentence_wer,\n",
    "    })\n",
    "\n",
    "# Create a results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results\n",
    "results_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\Comparison_Results.csv\"\n",
    "results_df.to_csv(results_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"Comparison results saved to: {results_path}\")\n",
    "\n",
    "# Calculate overall metrics\n",
    "total_sentences = len(results_df)\n",
    "exact_match_accuracy = results_df['Exact Match'].mean() * 100\n",
    "average_similarity = results_df['Similarity Score (%)'].mean()\n",
    "average_wer = results_df['Word Error Rate (WER)'].mean()\n",
    "\n",
    "# Display overall metrics\n",
    "print(f\"Total Sentences: {total_sentences}\")\n",
    "print(f\"Exact Match Accuracy: {exact_match_accuracy:.2f}%\")\n",
    "print(f\"Average Similarity Score: {average_similarity:.2f}%\")\n",
    "print(f\"Average Word Error Rate (WER): {average_wer:.2f}\")\n",
    "\n",
    "# Display top mismatched sentences\n",
    "mismatched_df = results_df[results_df['Exact Match'] == 0].sort_values(by='Similarity Score (%)', ascending=False)\n",
    "print(\"Top 5 Mismatched Sentences:\")\n",
    "print(mismatched_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity & Accuracy index for matched transcribe sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are aligned for comparison.\n",
      "Comparison results saved to: C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\Matched_Comparison_Results.csv\n",
      "Total Sentences: 340\n",
      "Exact Match Accuracy: 45.29%\n",
      "Average Similarity Score: 98.10%\n",
      "Average Word Error Rate (WER): 0.10\n",
      "Top 5 Mismatched Sentences:\n",
      "                                    Corrected Sentence  \\\n",
      "327  শুনলাম এ বারের বই মেলায় থিলার জনরার বেশ কিছু ব...   \n",
      "323  শুক্রবার দুপুরে পরিবারের সবাই মিলে বাইরে খেতে ...   \n",
      "203  বিকেলে বাসায় কিছু মেহমান আসবে, তাদের জন্য রান...   \n",
      "105  সামনে পহেলা বৈশাখে আমরা বাসার সবাই পাঞ্জাবি আর...   \n",
      "108  আমার বড় বোন ঈদে একটা শাড়ি চেয়েছিল, কিনতে ভু...   \n",
      "\n",
      "                                  Transcribed Sentence  Exact Match  \\\n",
      "327  শুন্লাম এ বারের বই মেলায় থিলার জনরার বেশ কিছু ...            0   \n",
      "323  শুক্রবার দুপুরে পরিবারে সবাই মিলে বাইরে খেতে গ...            0   \n",
      "203  বিকেলে বাসায় কিছু মেহমান আসবে তাদের জন্য রান্...            0   \n",
      "105  সামনে পহেলা বৈশাখে আমরা বাসার সবাই, পাঞ্জাবি আ...            0   \n",
      "108  আমার বড়ো বোন ঈদে একটা শাড়ি চেয়েছিল, কিনতে ভ...            0   \n",
      "\n",
      "     Similarity Score (%)  Edit Distance  Word Error Rate (WER)  \n",
      "327             99.186992              1               0.083333  \n",
      "323             99.159664              1               0.100000  \n",
      "203             99.145299              1               0.100000  \n",
      "105             99.130435              1               0.100000  \n",
      "108             99.130435              1               0.100000  \n",
      "Datasets are aligned for comparison.\n",
      "Comparison results saved to: C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\Comparison_Results.csv\n",
      "Total Sentences: 340\n",
      "Exact Match Accuracy: 6.47%\n",
      "Average Similarity Score: 86.74%\n",
      "Average Word Error Rate (WER): 0.46\n",
      "Top 5 Mismatched Sentences:\n",
      "                                    Corrected Sentence  \\\n",
      "199  আজকে পুরোনো বন্ধুদের সাথে দেখা হয়েছে, অনেক কথ...   \n",
      "338  তুমি পড়ালেখার পাশাপাশি ইন্টার্নশিপ করো, কাজে ...   \n",
      "276    এইবার ছুটিতে বন্ধুদের সাথে পাহাড়ে বেড়াতে যাব।   \n",
      "312    খুব ব্যস্ত দিন কাটালাম, এখন একটু বিশ্রাম দরকার।   \n",
      "122       তোমার পোশাকের ধরন আমার খুব একটা ভালো লাগেনি।   \n",
      "\n",
      "                                  Transcribed Sentence  Exact Match  \\\n",
      "199  আজকে পুরনো বন্ধুদের সাথে দেখা হয়েছে, অনেক কথা...            0   \n",
      "338  তুমি পড়ালেখার পাশাপাশি ইন্টারনশিপ করো, কাজে আ...            0   \n",
      "276   এইবার ছুটিতে বন্ধুদের সাথে পাহাড়ে বেড়াতে যাবে।            0   \n",
      "312     খুব ব্যস্ত দিন কাটালাম এখন একটু বিশ্রাম দরকার।            0   \n",
      "122      তোমার পোশাকের ধরন আমার খুব একটা ভালো লাগে নি।            0   \n",
      "\n",
      "     Similarity Score (%)  Edit Distance  Word Error Rate (WER)  \n",
      "199             99.029126              1               0.111111  \n",
      "338             99.009901              1               0.142857  \n",
      "276             98.947368              1               0.142857  \n",
      "312             98.924731              1               0.125000  \n",
      "122             98.876404              1               0.250000  \n"
     ]
    }
   ],
   "source": [
    "# Load the corrected and transcribed datasets\n",
    "corrected_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\CorrectSen - dementia.csv\"\n",
    "corrected_non_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\CorrectSen - NonDementia.csv\"\n",
    "\n",
    "transcribed_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\Final_Dementia_Transcriptions.csv\"\n",
    "transcribed_non_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\Final_NonDementia_Transcriptions.csv\"\n",
    "\n",
    "# Load datasets into DataFrames\n",
    "corrected_dementia_df = pd.read_csv(corrected_dementia_path)\n",
    "corrected_non_dementia_df = pd.read_csv(corrected_non_dementia_path)\n",
    "\n",
    "transcribed_dementia_df = pd.read_csv(transcribed_dementia_path)\n",
    "transcribed_non_dementia_df = pd.read_csv(transcribed_non_dementia_path)\n",
    "\n",
    "# Combine corrected and transcribed datasets for comparison\n",
    "corrected_df = pd.concat([corrected_dementia_df, corrected_non_dementia_df]).reset_index(drop=True)\n",
    "transcribed_df = pd.concat([transcribed_dementia_df, transcribed_non_dementia_df]).reset_index(drop=True)\n",
    "\n",
    "# Ensure the datasets are aligned\n",
    "if len(corrected_df) != len(transcribed_df):\n",
    "    print(\"Warning: The datasets have different numbers of sentences!\")\n",
    "else:\n",
    "    print(\"Datasets are aligned for comparison.\")\n",
    "\n",
    "# Compare sentences\n",
    "results = []\n",
    "for index, row in corrected_df.iterrows():\n",
    "    corrected_sentence = row['sentences']  # Assuming 'sentences' column in corrected_df\n",
    "    transcribed_sentence = transcribed_df.loc[index, 'transcribed_text']  # 'transcribed_text' in transcribed_df\n",
    "\n",
    "    # Calculate metrics\n",
    "    exact_match = int(corrected_sentence.strip() == transcribed_sentence.strip())\n",
    "    similarity_score = fuzz.ratio(corrected_sentence, transcribed_sentence)\n",
    "    edit_distance = Levenshtein.distance(corrected_sentence, transcribed_sentence)  # Updated line\n",
    "    sentence_wer = wer(corrected_sentence, transcribed_sentence)\n",
    "\n",
    "\n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Corrected Sentence': corrected_sentence,\n",
    "        'Transcribed Sentence': transcribed_sentence,\n",
    "        'Exact Match': exact_match,\n",
    "        'Similarity Score (%)': similarity_score,\n",
    "        'Edit Distance': edit_distance,\n",
    "        'Word Error Rate (WER)': sentence_wer,\n",
    "    })\n",
    "\n",
    "# Create a results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results\n",
    "results_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\Matched_Comparison_Results.csv\"\n",
    "results_df.to_csv(results_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"Comparison results saved to: {results_path}\")\n",
    "\n",
    "# Calculate overall metrics\n",
    "total_sentences = len(results_df)\n",
    "exact_match_accuracy = results_df['Exact Match'].mean() * 100\n",
    "average_similarity = results_df['Similarity Score (%)'].mean()\n",
    "average_wer = results_df['Word Error Rate (WER)'].mean()\n",
    "\n",
    "# Display overall metrics\n",
    "print(f\"Total Sentences: {total_sentences}\")\n",
    "print(f\"Exact Match Accuracy: {exact_match_accuracy:.2f}%\")\n",
    "print(f\"Average Similarity Score: {average_similarity:.2f}%\")\n",
    "print(f\"Average Word Error Rate (WER): {average_wer:.2f}\")\n",
    "\n",
    "# Display top mismatched sentences\n",
    "mismatched_df = results_df[results_df['Exact Match'] == 0].sort_values(by='Similarity Score (%)', ascending=False)\n",
    "print(\"Top 5 Mismatched Sentences:\")\n",
    "print(mismatched_df.head(5))# Load the corrected and transcribed datasets\n",
    "corrected_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\CorrectSen - dementia.csv\"\n",
    "corrected_non_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\CorrectSen - NonDementia.csv\"\n",
    "\n",
    "transcribed_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\Dementia_Transcriptions.csv\"\n",
    "transcribed_non_dementia_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\NonDementia_Transcriptions.csv\"\n",
    "\n",
    "# Load datasets into DataFrames\n",
    "corrected_dementia_df = pd.read_csv(corrected_dementia_path)\n",
    "corrected_non_dementia_df = pd.read_csv(corrected_non_dementia_path)\n",
    "\n",
    "transcribed_dementia_df = pd.read_csv(transcribed_dementia_path)\n",
    "transcribed_non_dementia_df = pd.read_csv(transcribed_non_dementia_path)\n",
    "\n",
    "# Combine corrected and transcribed datasets for comparison\n",
    "corrected_df = pd.concat([corrected_dementia_df, corrected_non_dementia_df]).reset_index(drop=True)\n",
    "transcribed_df = pd.concat([transcribed_dementia_df, transcribed_non_dementia_df]).reset_index(drop=True)\n",
    "\n",
    "# Ensure the datasets are aligned\n",
    "if len(corrected_df) != len(transcribed_df):\n",
    "    print(\"Warning: The datasets have different numbers of sentences!\")\n",
    "else:\n",
    "    print(\"Datasets are aligned for comparison.\")\n",
    "\n",
    "# Compare sentences\n",
    "results = []\n",
    "for index, row in corrected_df.iterrows():\n",
    "    corrected_sentence = row['sentences']  # Assuming 'sentences' column in corrected_df\n",
    "    transcribed_sentence = transcribed_df.loc[index, 'transcribed_text']  # 'transcribed_text' in transcribed_df\n",
    "\n",
    "    # Calculate metrics\n",
    "    exact_match = int(corrected_sentence.strip() == transcribed_sentence.strip())\n",
    "    similarity_score = fuzz.ratio(corrected_sentence, transcribed_sentence)\n",
    "    edit_distance = Levenshtein.distance(corrected_sentence, transcribed_sentence)  # Updated line\n",
    "    sentence_wer = wer(corrected_sentence, transcribed_sentence)\n",
    "\n",
    "\n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Corrected Sentence': corrected_sentence,\n",
    "        'Transcribed Sentence': transcribed_sentence,\n",
    "        'Exact Match': exact_match,\n",
    "        'Similarity Score (%)': similarity_score,\n",
    "        'Edit Distance': edit_distance,\n",
    "        'Word Error Rate (WER)': sentence_wer,\n",
    "    })\n",
    "\n",
    "# Create a results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results\n",
    "results_path = r\"C:\\Users\\AsifAK\\Desktop\\Code_Detect_Dementia\\Comparison_Results.csv\"\n",
    "results_df.to_csv(results_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"Comparison results saved to: {results_path}\")\n",
    "\n",
    "# Calculate overall metrics\n",
    "total_sentences = len(results_df)\n",
    "exact_match_accuracy = results_df['Exact Match'].mean() * 100\n",
    "average_similarity = results_df['Similarity Score (%)'].mean()\n",
    "average_wer = results_df['Word Error Rate (WER)'].mean()\n",
    "\n",
    "# Display overall metrics\n",
    "print(f\"Total Sentences: {total_sentences}\")\n",
    "print(f\"Exact Match Accuracy: {exact_match_accuracy:.2f}%\")\n",
    "print(f\"Average Similarity Score: {average_similarity:.2f}%\")\n",
    "print(f\"Average Word Error Rate (WER): {average_wer:.2f}\")\n",
    "\n",
    "# Display top mismatched sentences\n",
    "mismatched_df = results_df[results_df['Exact Match'] == 0].sort_values(by='Similarity Score (%)', ascending=False)\n",
    "print(\"Top 5 Mismatched Sentences:\")\n",
    "print(mismatched_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word frequencies by class have been saved to 'word_frequencies_by_class.csv' successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset\n",
    "# Replace 'Merged_Dataset.csv' with the actual file path of your dataset\n",
    "df = pd.read_csv('Merged_Dataset.csv')\n",
    "\n",
    "# Check if the necessary columns exist\n",
    "if 'transcribed_text' in df.columns and 'class' in df.columns:\n",
    "    # Separate the data by class\n",
    "    dementia_sentences = df[df['class'] == 'Dementia']['transcribed_text'].dropna().tolist()\n",
    "    non_dementia_sentences = df[df['class'] == 'Non-Dementia']['transcribed_text'].dropna().tolist()\n",
    "\n",
    "    # Tokenize words for each class\n",
    "    dementia_words = []\n",
    "    for sentence in dementia_sentences:\n",
    "        tokens = re.findall(r'[\\u0980-\\u09FF]+', sentence)  # Match Bangla words\n",
    "        dementia_words.extend(tokens)\n",
    "\n",
    "    non_dementia_words = []\n",
    "    for sentence in non_dementia_sentences:\n",
    "        tokens = re.findall(r'[\\u0980-\\u09FF]+', sentence)  # Match Bangla words\n",
    "        non_dementia_words.extend(tokens)\n",
    "\n",
    "    # Count word frequencies for each class\n",
    "    dementia_word_counts = Counter(dementia_words)\n",
    "    non_dementia_word_counts = Counter(non_dementia_words)\n",
    "\n",
    "    # Create a unified DataFrame\n",
    "    all_words = set(dementia_word_counts.keys()).union(set(non_dementia_word_counts.keys()))\n",
    "    data = {\n",
    "        'Word': list(all_words),\n",
    "        'Dementia_Frequency': [dementia_word_counts.get(word, 0) for word in all_words],\n",
    "        'Non_Dementia_Frequency': [non_dementia_word_counts.get(word, 0) for word in all_words]\n",
    "    }\n",
    "\n",
    "    word_frequencies_df = pd.DataFrame(data).sort_values(by=['Dementia_Frequency', 'Non_Dementia_Frequency'], ascending=False)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    output_file = 'word_frequencies_by_class.csv'\n",
    "    word_frequencies_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"Word frequencies by class have been saved to '{output_file}' successfully.\")\n",
    "else:\n",
    "    print(\"The necessary columns 'transcribed_text' or 'class' are not found in the dataset.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
